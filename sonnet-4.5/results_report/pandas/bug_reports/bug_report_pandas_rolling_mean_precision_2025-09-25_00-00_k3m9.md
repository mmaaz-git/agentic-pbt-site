# Bug Report: pandas.core.window.Rolling.mean Precision Error with Large Values

**Target**: `pandas.core.window.Rolling.mean`
**Severity**: High
**Bug Type**: Logic
**Date**: 2025-09-25

## Summary

The rolling mean calculation in pandas accumulates precision errors when the series contains very large numbers, causing subsequent window calculations to return wildly incorrect results that violate the fundamental property that mean must be between min and max.

## Property-Based Test

```python
import math

import pandas as pd
from hypothesis import assume, given, settings, strategies as st


@given(
    st.lists(
        st.floats(allow_nan=False, allow_infinity=False, min_value=-1e10, max_value=1e10),
        min_size=1,
        max_size=100,
    ),
    st.integers(min_value=1, max_value=10),
)
@settings(max_examples=500)
def test_rolling_min_max_bounds(data, window):
    assume(window <= len(data))
    s = pd.Series(data)

    rolling_min = s.rolling(window=window).min()
    rolling_max = s.rolling(window=window).max()
    rolling_mean = s.rolling(window=window).mean()

    for i in range(window - 1, len(data)):
        min_val = rolling_min.iloc[i]
        max_val = rolling_max.iloc[i]
        mean_val = rolling_mean.iloc[i]

        assert min_val <= mean_val or math.isclose(min_val, mean_val, rel_tol=1e-9, abs_tol=1e-9), \
            f"At {i}: rolling_min {min_val} > rolling_mean {mean_val}"
        assert mean_val <= max_val or math.isclose(mean_val, max_val, rel_tol=1e-9, abs_tol=1e-9), \
            f"At {i}: rolling_mean {mean_val} > rolling_max {max_val}"
```

**Failing input**: `data=[1.0, -4294967297.0, 0.99999, 0.0, 0.0, 1.6675355247098508e-21], window=3`

## Reproducing the Bug

```python
import pandas as pd

data = [1.0, -4294967297.0, 0.99999, 0.0, 0.0, 1.6675355247098508e-21]
s = pd.Series(data)
rolling_mean = s.rolling(window=3).mean()

window_at_5 = data[3:6]
expected_mean = sum(window_at_5) / 3
actual_mean = rolling_mean.iloc[5]

print(f"Window at index 5: {window_at_5}")
print(f"Expected mean: {expected_mean}")
print(f"Pandas returns: {actual_mean}")
print(f"Bug: mean ({actual_mean}) > max ({max(window_at_5)})")
```

Output:
```
Window at index 5: [0.0, 0.0, 1.6675355247098508e-21]
Expected mean: 5.558451749032836e-22
Pandas returns: 1.5894571940104224e-07
Bug: mean (1.5894571940104224e-07) > max (1.6675355247098508e-21)
```

## Why This Is A Bug

1. **Violates mathematical invariant**: The mean of a set of numbers must always be between the minimum and maximum values. Here, the rolling mean (1.59e-07) is greater than the rolling max (1.67e-21), which is mathematically impossible.

2. **Silent data corruption**: The result is wrong by approximately 14 orders of magnitude (relative error > 10^16%), but no warning or error is raised.

3. **Triggered by large values**: The bug only appears when the series contains very large numbers (here, -4294967297 â‰ˆ -2^32). Without this large value, the calculation is correct.

4. **Persistence across windows**: The precision error from the large number contaminates subsequent window calculations that don't even include that large number.

## Fix

This appears to be a precision accumulation error in the rolling mean implementation, likely in the Cython code that handles the rolling calculations. The rolling mean algorithm is probably using an incremental update approach (like Welford's algorithm) that accumulates floating-point errors when dealing with numbers of vastly different magnitudes.

A potential fix would be to:
- Use a more numerically stable algorithm (e.g., Kahan summation)
- Reset accumulated errors when the window slides past values with extreme magnitudes
- Use higher precision arithmetic for the accumulator when detecting large value ranges

Without access to the Cython implementation code, a specific patch cannot be provided, but the fix should focus on improving numerical stability in the rolling window calculations when handling values with extreme magnitudes.
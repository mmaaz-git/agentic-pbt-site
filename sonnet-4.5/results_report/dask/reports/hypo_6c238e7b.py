#!/usr/bin/env python3
"""
Property-based test for dask.bytes.read_bytes offset generation.
Tests the invariant that offsets should be strictly increasing.
"""

from hypothesis import given, strategies as st, settings

@given(
    st.integers(min_value=1, max_value=100000),
    st.integers(min_value=1, max_value=10000),
    st.booleans()
)
@settings(max_examples=500)
def test_blocksize_calculation_invariants(size, blocksize, not_zero):
    """
    Test that offsets generated by the read_bytes logic are strictly increasing.
    This is a fundamental invariant - blocks should not overlap.
    """
    # Simulate the exact logic from dask.bytes.core.read_bytes
    if size % blocksize and size > blocksize:
        blocksize1 = size / (size // blocksize)
    else:
        blocksize1 = blocksize

    place = 0
    off = [0]
    length = []

    while size - place > (blocksize1 * 2) - 1:
        place += blocksize1
        off.append(int(place))
        length.append(off[-1] - off[-2])
    length.append(size - off[-1])

    if not_zero:
        off[0] = 1
        length[0] -= 1

    # Check the invariant: offsets must be strictly increasing
    for i in range(1, len(off)):
        assert off[i] > off[i-1], (
            f"Offsets not increasing at index {i}: "
            f"off={off}, size={size}, blocksize={blocksize}, not_zero={not_zero}"
        )

if __name__ == "__main__":
    print("Running property-based test for dask.bytes.read_bytes offset generation...")
    print("Testing invariant: offsets must be strictly increasing")
    print()

    try:
        test_blocksize_calculation_invariants()
        print("All tests passed!")
    except AssertionError as e:
        print(f"Test failed with assertion error:")
        print(f"  {e}")
        print()
        print("This demonstrates a bug where duplicate offsets are generated,")
        print("violating the fundamental assumption that file blocks don't overlap.")
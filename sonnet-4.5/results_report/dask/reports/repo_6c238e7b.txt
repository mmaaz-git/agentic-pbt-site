=== Reproducing dask.bytes.read_bytes duplicate offset bug ===
Input parameters:
  size = 2
  blocksize = 1
  not_zero = True

Generated offsets: [1, 1]
Generated lengths: [0, 1]

=== Bug Analysis ===
BUG DETECTED: Duplicate offsets found!
  offsets[0] = 1
  offsets[1] = 1

This violates the invariant that offsets should be strictly increasing.
Two blocks would start reading from the same position in the file,
causing data duplication or loss.

=== Offset Invariant Check ===
INVARIANT VIOLATED at index 1:
  offsets[0] = 1
  offsets[1] = 1
  Expected: offsets[1] > offsets[0]

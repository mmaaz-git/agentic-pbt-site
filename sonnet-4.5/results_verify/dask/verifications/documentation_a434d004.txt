DOCUMENTATION ANALYSIS

1. CLASS DOCSTRING:
The LRU class has a docstring that states: "Limited size mapping, evicting the least recently looked-up key when full"

This clearly indicates the intended behavior:
- It's a limited size mapping (dictionary-like structure)
- When full, it should evict the LEAST recently looked-up key
- "Looked-up" implies accessed via __getitem__

2. IMPLEMENTATION DETAILS:
The class inherits from UserDict and uses OrderedDict as its internal storage:
- __getitem__ moves accessed keys to the end of the OrderedDict (marking them as recently used)
- __setitem__ is supposed to handle eviction when the cache is full
- OrderedDict.popitem(last=False) removes the first item (least recently used)

3. STANDARD LRU SEMANTICS:
According to Wikipedia and standard computer science definitions:
- LRU (Least Recently Used) caches track when each item was last accessed
- When the cache is full and a new item needs to be added, the item that hasn't been accessed for the longest time is evicted
- Accessing an item updates its "last accessed" time, moving it to the most recently used position

4. EXPECTED BEHAVIOR:
Based on the documentation and standard LRU semantics:
- Accessing an item should mark it as recently used
- When adding a new item to a full cache, the least recently used item should be evicted
- Updating an existing key should NOT trigger eviction (cache size doesn't change)

5. CURRENT BUG:
The current implementation violates these expectations:
- It unconditionally evicts when len(self) >= maxsize, even when updating existing keys
- This causes existing keys to be removed and re-added unnecessarily

6. EDGE CASE CONSIDERATION:
For maxsize=1:
- There's only room for one item
- When adding a NEW item, the existing item must be evicted (no other choice)
- However, updating the existing item should not cause eviction

The documentation clearly supports that this is a bug in the implementation, particularly for the case of updating existing keys.
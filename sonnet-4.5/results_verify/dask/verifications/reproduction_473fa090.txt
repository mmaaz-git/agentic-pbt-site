REPRODUCTION ANALYSIS
====================

The bug report is confirmed and reproducible.

## Test Results

1. **Direct Bug Reproduction**:
   - The exact test case provided in the bug report was successfully reproduced
   - Input: statistics with first row having min=None, max=None and second row having min=0, max=None
   - Result: TypeError: '>=' not supported between instances of 'int' and 'NoneType'
   - Error occurs at line 433 in sorted_columns function

2. **Hypothesis Testing**:
   - The Hypothesis property-based test found multiple distinct failure scenarios
   - Common patterns include:
     a. TypeError when comparing int with NoneType ('>=' operator)
     b. TypeError when comparing NoneType with int ('<' operator in sorting)
   - The test discovered various combinations where None values in min/max fields cause crashes

## Root Cause

The function `sorted_columns` in `/home/npc/pbt/agentic-pbt/envs/dask_env/lib/python3.13/site-packages/dask/dataframe/io/parquet/core.py`:

1. Line 426 initializes `max = c["max"]` which can be None
2. Line 430-432 checks if `c["min"]` is None and breaks if true
3. Line 433 performs comparison `c["min"] >= max` without checking if `max` is None
4. When max is None and c["min"] is an integer, Python raises TypeError

## Impact

The bug occurs when processing parquet file statistics with incomplete or missing min/max values. This is a realistic scenario that can happen with:
- Corrupted parquet files
- Parquet files with incomplete statistics
- Null-only columns
- Edge cases in data processing pipelines

The crash prevents reading such parquet files entirely, even though the data itself might be intact.
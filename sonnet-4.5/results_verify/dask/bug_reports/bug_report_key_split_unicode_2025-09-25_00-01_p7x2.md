# Bug Report: key_split Crashes on Non-UTF-8 Bytes

**Target**: `dask.utils.key_split`
**Severity**: Medium
**Bug Type**: Crash
**Date**: 2025-09-25

## Summary

The `key_split` function crashes with `UnicodeDecodeError` when given non-UTF-8 bytes, despite accepting bytes as input (shown in docstring examples).

## Property-Based Test

```python
from hypothesis import given, strategies as st, settings
from dask.utils import key_split


@given(st.binary())
@settings(max_examples=300)
def test_key_split_bytes(b):
    result = key_split(b)
    assert isinstance(result, str), f"key_split should return str for bytes, got {type(result)}"
```

**Failing input**: `b=b'\x80'`

## Reproducing the Bug

```python
from dask.utils import key_split

result = key_split(b'\x80')
```

Output:
```
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte
```

The function handles UTF-8 bytes correctly (as shown in the docstring example `key_split(b'hello-world-1')`) but fails on invalid UTF-8 sequences.

## Why This Is A Bug

1. The function's docstring includes an example with bytes input: `key_split(b'hello-world-1')`, indicating bytes are a valid input type
2. The function has exception handling that returns "Other" for problematic inputs (e.g., `key_split(None)` â†’ `'Other'`)
3. Non-UTF-8 bytes are valid Python bytes objects that should be handled gracefully, not crash

## Fix

The fix is to handle `UnicodeDecodeError` when decoding bytes:

```diff
--- a/dask/utils.py
+++ b/dask/utils.py
@@ -1976,7 +1976,10 @@ def key_split(s):
     """
     # If we convert the key, recurse to utilize LRU cache better
     if type(s) is bytes:
-        return key_split(s.decode())
+        try:
+            return key_split(s.decode())
+        except UnicodeDecodeError:
+            return "Other"
     if type(s) is tuple:
         return key_split(s[0])
     try:
```

This makes the function handle non-UTF-8 bytes the same way it handles other problematic inputs - by returning "Other".
## Bug Reproduction Results

### Test 1: pd.cut with very small float
Input: `values = [0.0, 0.0, 0.0, 2.2250738585e-313, -1.0]`, `bins=2`
Result: **FAILED** with ValueError: "missing values must be missing in the same location both left and right sides"

The bug report's claim is confirmed - pd.cut crashes with this input.

### Test 2: pd.qcut with very small float
Input: `values = [0.0, 0.0, 0.0, 1.0, 2.2250738585072014e-308]`, `q=3`
Result: **FAILED** with same ValueError as Test 1

The bug report's claim is confirmed for qcut as well.

### Root Cause Analysis
Direct testing of the `_round_frac` function confirms the bug report's analysis:

1. For `x = 2.2250738585e-313` with `precision = 3`:
   - `np.modf()` returns `(frac=2.225e-313, whole=0.0)`
   - Since `whole == 0`, it calculates: `digits = -int(floor(log10(2.225e-313))) - 1 + 3 = 315`
   - `np.around(2.225e-313, 315)` returns `NaN`

2. Testing shows `np.around()` produces NaN starting at 309 decimal places for this value

3. The NaN values propagate through the binning process, causing IntervalArray validation to fail

### Mathematical Verification
The bug report's mathematical analysis is correct:
- `log10(2.225e-313) â‰ˆ -312.65`
- `floor(-312.65) = -313`
- `digits = -(-313) - 1 + 3 = 315`

### Additional Findings
- The issue occurs with denormalized floating-point numbers (values very close to zero)
- `np.around()` has an undocumented limitation: it produces NaN when asked to round to >308 decimal places
- Values like 1e-100 work fine because they only require 102 decimal places
- The threshold appears to be around 1e-307, where the required decimal places exceed numpy's limit

### Conclusion
The bug report is technically accurate. The functions do crash when given very small floating-point numbers due to an overflow in the number of decimal places passed to `np.around()`, which then returns NaN, causing downstream failures.
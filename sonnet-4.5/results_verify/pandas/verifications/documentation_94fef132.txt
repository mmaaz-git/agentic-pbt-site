## Documentation Analysis Report

### Official pandas.DataFrame.to_json() Documentation
The official documentation (pandas.pydata.org) describes the following:
- **Parameters**: path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options, mode
- **No 'errors' parameter** for handling encoding errors
- **force_ascii parameter**: "Forces encoded string to be ASCII" (default True)
- **Exceptions mentioned**: Only ValueError for invalid double_precision or orient/lines combinations
- **No mention of**: UnicodeEncodeError, surrogate characters, or UTF-8 encoding issues

### Key Documentation Gaps
1. **No warning about Unicode surrogates**: The documentation doesn't mention that surrogate characters will cause crashes
2. **No error handling guidance**: Unlike to_csv() which has an 'errors' parameter, to_json() provides no way to handle encoding errors
3. **Misleading force_ascii description**: The parameter name suggests it might help with non-ASCII characters, but it doesn't prevent the surrogate error

### Related pandas Issues
- **GitHub Issue #22610**: Similar problem with to_csv() and surrogates, which was fixed by adding an 'errors' parameter
- **Solution precedent**: The pandas team already recognized this as a valid issue for to_csv() and implemented error handling

### JSON Specification Context
- JSON (RFC 7159) allows Unicode escape sequences like \uD800
- Surrogates are valid in JSON when properly escaped
- The crash happens before JSON encoding, during internal UTF-8 conversion

### Documentation vs Implementation
The documentation doesn't specify behavior for characters that cannot be encoded to UTF-8. Given that:
1. Python strings can contain surrogates
2. JSON can represent surrogates (escaped)
3. to_csv() already handles this scenario with an errors parameter
4. The function crashes rather than handling the error gracefully

The lack of documentation about this limitation combined with the existence of a solution in to_csv() suggests this is an implementation gap rather than intended behavior.